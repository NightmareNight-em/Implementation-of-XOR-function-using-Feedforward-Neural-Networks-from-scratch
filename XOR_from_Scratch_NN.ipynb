{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Harshit_Nigam_Backpropagation_XOR_f (2).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ly0FEPLRRA3R"
      },
      "source": [
        "## Implementing Back-propagation Algorithm with XOR data\n",
        "\n",
        "### XOR data: <br>\n",
        "**$ x_0 \\ x_1 \\ y$** <br>\n",
        "$0 \\ \\ \\  0 \\ \\ \\  0$ <br>\n",
        "$0 \\ \\ \\  1 \\ \\ \\  1$ <br>\n",
        "$1 \\ \\ \\  0 \\ \\ \\  1$<br>\n",
        "$1 \\ \\ \\  1 \\ \\ \\  0$<br>\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Iewd7ysumt1L",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xYnKrpHRC88X"
      },
      "source": [
        "##Activation function\n",
        "\n",
        "Sigmoid function $$\\frac{1}{1+ e^{-x}} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "id": "RR5ReWLb0rQ8",
        "nbgrader": {
          "checksum": "f4effe0bb558b3f87da12a7a5133ee75",
          "grade": false,
          "grade_id": "cell-d84ad9dbcb889c3f",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "colab": {}
      },
      "source": [
        "#Define our activation function\n",
        "\n",
        "def sigmoid (x):\n",
        "    '''\n",
        "    Input:\n",
        "        x: numpy array of any shape\n",
        "    Output:\n",
        "        y: numpy array of same shape as x\n",
        "    '''\n",
        "    # YOUR CODE HERE\n",
        "    return 1/(1+np.exp(-x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "editable": false,
        "id": "4q5l-n3LkamT",
        "nbgrader": {
          "checksum": "8556b6d6d8fb50561b6a4b23e4f428e2",
          "grade": true,
          "grade_id": "cell-80b53c7b5034f924",
          "locked": true,
          "points": 1,
          "schema_version": 1,
          "solution": false
        },
        "outputId": "a8f52c35-44ce-48f0-b475-4c4359537e23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "'''Testing'''\n",
        "assert sigmoid(0)==0.5\n",
        "assert np.isclose(sigmoid(-2), 0.119202922, atol=0.0001)\n",
        "print('Test passed', '\\U0001F44D')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test passed üëç\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "id": "hAS1d1_Wkama",
        "nbgrader": {
          "checksum": "b5988d9e371e77c56c63d315f5c63d3e",
          "grade": false,
          "grade_id": "cell-9ebb909521c85d2b",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "colab": {}
      },
      "source": [
        "# Define the activation function derivative\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    '''\n",
        "    Input:\n",
        "        x: numpy array of any shape\n",
        "    Output:\n",
        "        y: numpy array of same shape as x\n",
        "        y = derivative of sigmoid\n",
        "    '''\n",
        "    # YOUR CODE HERE\n",
        "    return x*(1-x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "editable": false,
        "id": "D27idxL-kami",
        "nbgrader": {
          "checksum": "d980605ecd57b9e69ac9a07ec6cfbc06",
          "grade": true,
          "grade_id": "cell-8668ae928d66bf7c",
          "locked": true,
          "points": 1,
          "schema_version": 1,
          "solution": false
        },
        "outputId": "8ac00953-a34c-4d9e-a960-eaa3a39c90d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "'''Testing code for sigmoid_derivative'''\n",
        "assert sigmoid_derivative(1) == 0\n",
        "assert sigmoid_derivative(0) == 0\n",
        "print('Test passed', '\\U0001F44D')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test passed üëç\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7QEVx1qpYo3m"
      },
      "source": [
        "## Defining the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "id": "QiXPUCkdP5ky",
        "nbgrader": {
          "checksum": "4646c91497019ffdff3cd615c01b92a9",
          "grade": false,
          "grade_id": "cell-4a7dcd60006d48dc",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "colab": {}
      },
      "source": [
        "#Define the NeuralNetwork class\n",
        "\n",
        "class NeuralNetwork:\n",
        "    def __init__(self, net_arch):\n",
        "        '''   \n",
        "        Input:\n",
        "            net_arch: list of 3 integers\n",
        "        Action:\n",
        "            Creates instance variables:\n",
        "                self.input: np array of shape (ni,1)\n",
        "                self.layer1: nprarray of shape (nh,1)\n",
        "                self.output: np array of shape (no,1)\n",
        "                self.weights1: np array of shape (nh, ni), initialized randomly between (-1,1)\n",
        "                self.weights2: np array of shape (no, nh), initialized randomly between (-1,1)\n",
        "                \n",
        "            NOTE: We do not use bias explicitly here. Input x can have the first element 1 to have a bias term.\n",
        "        '''\n",
        "        ni = net_arch[0]  ## Number of neurons in input layer    \n",
        "        nh = net_arch[1]  ## Number of neurons in hidden layer\n",
        "        no = net_arch[2]  ## Number of neurons in output layer\n",
        "        \n",
        "        self.ni = ni\n",
        "        self.nh = nh\n",
        "        self.no = no\n",
        "        \n",
        "        # YOUR CODE HERE\n",
        "        self.input=np.empty((ni,1))\n",
        "        self.layer1=np.empty((nh,1))\n",
        "        self.output=np.empty((no,1))\n",
        "        self.weights1=(2*np.random.rand(nh,ni)-1)/2\n",
        "        self.weights2=(2*np.random.rand(no,nh)-1)/2\n",
        "        \n",
        "    def feedforward(self,x):\n",
        "        '''\n",
        "        Input:\n",
        "            x: numpy array of shape (ni,1)\n",
        "        Action:\n",
        "            \n",
        "        Return:\n",
        "            output: numpy array of shape (no,1),\n",
        "        '''\n",
        "        # YOUR CODE HERE\n",
        "        h1=np.array([])\n",
        "        v1=np.array([])\n",
        "        h2=np.array([])\n",
        "        h1=self.weights1.dot(x[:(self.ni),:])\n",
        "        v1=sigmoid(h1)\n",
        "        self.layer1=v1\n",
        "        h2=self.weights2.dot(v1)\n",
        "        output=sigmoid(h2)\n",
        "        return output\n",
        "             \n",
        "\n",
        "    def backprop(self,x,y,eta):\n",
        "        '''\n",
        "        # application of the chain rule to find derivative of the loss function with respect to weights2 and weights1\n",
        "        Input:\n",
        "            x: numpy array of shape (ni,1)\n",
        "            y: numpy array of shape (no,1)\n",
        "            eta: learning rate\n",
        "        Action:\n",
        "        # Finding the derivatives\n",
        "            del_weights2: np array of shape (no,nh) that stores the derivative of the loss function with respect to weights2\n",
        "            del_weights1: np array of shape (nh,ni) that stores the derivative of the loss function with respect to weights1\n",
        "            \n",
        "        # Update the weights with the derivative of the loss function\n",
        "            weights1 += eta*del_weights1\n",
        "            weights2 += eta*del_weights2\n",
        "        '''\n",
        "        e=y-self.output\n",
        "        del_weights2=np.dot((e*sigmoid_derivative(y)),self.layer1.T)\n",
        "        print(del_weights2.shape)\n",
        "        print(self.layer1)\n",
        "        print(x)\n",
        "        del_weights1=np.dot(((sigmoid_derivative(self.layer1.T))*del_weights2*self.weights2).T,x.T)\n",
        "        self.weights2+=eta*del_weights2\n",
        "        self.weights1+=eta*del_weights1\n",
        "   \n",
        "\n",
        "\n",
        "    def fit(self, X, Y, eta, epochs):\n",
        "        '''\n",
        "        input:\n",
        "        X: training input data of shape (4,2)\n",
        "        Y: training output of shape (4,1)\n",
        "        eta: learning rate\n",
        "        epochs: number of epochs\n",
        "        Action:\n",
        "        # Modify the input by adding ones of shape(4,1) \n",
        "        # Set up the feed-forward propagation for the modified input   \n",
        "        # Set up the back-propagation of the error to adjust the weights\n",
        "        '''\n",
        "        # YOUR CODE HERE\n",
        "        for i in range(epochs):\n",
        "          #X=np.hstack((X,(np.ones(4,1))))\n",
        "          a = np.ones((4,1))\n",
        "          x = np.add(X,a)\n",
        "          self.output=feedforward(self,x)\n",
        "          backprop(self,X,Y,eta)\n",
        "          \n",
        "          \n",
        "        \n",
        "        \n",
        "        \n",
        "    def predict(self,x,y):\n",
        "        '''\n",
        "        # Predict function is used to check the prediction result of the neural network\n",
        "        Input:\n",
        "        x: single input data of shape (1,3)\n",
        "        y: single output data of shape (1,1)\n",
        "        Action\n",
        "        pred_out: predict the output based on the model using feedforward\n",
        "        \n",
        "        Output\n",
        "        error: y - pred_out\n",
        "        \n",
        "        \n",
        "        '''\n",
        "        # YOUR CODE HERE\n",
        "        y1=feedforward(self,x.T)\n",
        "        error=y1-y\n",
        "        return(error)\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "editable": false,
        "id": "6gp5eg0skamy",
        "nbgrader": {
          "checksum": "01c984c866bc53a22934b3a8a85bb6ae",
          "grade": true,
          "grade_id": "cell-640694d6a41609e8",
          "locked": true,
          "points": 2,
          "schema_version": 1,
          "solution": false
        },
        "outputId": "6806d358-5ac1-4934-91bd-0157c58fa344",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "'''Testing code for __init__'''\n",
        "\n",
        "net_arch = [3,4,1]\n",
        "nn1 = NeuralNetwork(net_arch)\n",
        "assert nn1.input.shape==(3,1)\n",
        "assert nn1.layer1.shape == (4,1)\n",
        "assert nn1.output.shape == (1,1)\n",
        "assert np.all(nn1.weights1 < 1)\n",
        "print('Test passed', '\\U0001F44D')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test passed üëç\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "editable": false,
        "id": "hP6uPl-2kanA",
        "nbgrader": {
          "checksum": "2bcf8c9fbcf3690b31a8c6a9cde70928",
          "grade": true,
          "grade_id": "cell-f0a271c06ea8c25b",
          "locked": true,
          "points": 2,
          "schema_version": 1,
          "solution": false
        },
        "outputId": "5c0f27eb-a175-418c-8826-305edf6125e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "'''Testing code for feedforward'''\n",
        "\n",
        "def feedforward_original(nn1,x):\n",
        "    assert x.shape == (nn1.ni, 1)\n",
        "    layer1 = sigmoid(np.dot(nn1.weights1, x))\n",
        "    output = sigmoid(np.dot(nn1.weights2, layer1))\n",
        "    return output\n",
        "x = np.array([0,1,1]).reshape(-1, 1)\n",
        "assert nn1.feedforward(x) == feedforward_original(nn1, x)\n",
        "print('Test passed', '\\U0001F44D')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test passed üëç\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "editable": false,
        "id": "XBXXqFAKYxnv",
        "nbgrader": {
          "checksum": "3737666b17aaad1d4a58603c7b67ce81",
          "grade": true,
          "grade_id": "cell-a4a2893378d844f3",
          "locked": true,
          "points": 4,
          "schema_version": 1,
          "solution": false
        },
        "outputId": "8e7bc172-e421-4dd6-8a82-8b4e18717296",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        }
      },
      "source": [
        "'''Testing code for backprop'''\n",
        "def backprop_original(nn1,x,y,eta):\n",
        "    weights1 = nn1.weights1\n",
        "    weights2 = nn1.weights2\n",
        "    del_weights2 = np.dot(((y - nn1.output) * sigmoid_derivative(nn1.output)),nn1.layer1.reshape(-1, 1).T)\n",
        "    del_weights1 = np.dot(((y - nn1.output) * sigmoid_derivative(nn1.output)*nn1.weights2.T * sigmoid_derivative(nn1.layer1)), x.T)\n",
        "\n",
        "    # update the weights with the derivative (slope) of the loss function\n",
        "    weights1 += eta*del_weights1\n",
        "    weights2 += eta*del_weights2\n",
        "    return(weights1, weights2)\n",
        "\n",
        "x = np.array([0,1,1]).reshape(-1, 1)\n",
        "y = np.array([[0],])\n",
        "eta = 1\n",
        "nn1.backprop(x, y, eta)\n",
        "w1, w2 = backprop_original(nn1, x, y, eta) \n",
        "assert np.all(np.isclose(w1, nn1.weights1))\n",
        "assert np.all(np.isclose(w2, nn1.weights2))\n",
        "print('Test passed', '\\U0001F44D')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 4)\n",
            "[[0.31316231]\n",
            " [0.53597592]\n",
            " [0.51656296]\n",
            " [0.41042472]]\n",
            "[[0]\n",
            " [1]\n",
            " [1]]\n",
            "Test passed üëç\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tUs7Wwu7ZjBX"
      },
      "source": [
        "## Fitting the data (Training)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "id": "kbRcD6R6RBpw",
        "nbgrader": {
          "checksum": "dbbf11073bfdce0010e10e0eaca6500c",
          "grade": false,
          "grade_id": "cell-e59bb4a5a7ddab07",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "outputId": "d6e2472d-0461-4143-cead-0103a014c9d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        }
      },
      "source": [
        "## CHECK THE PERFORMANCE\n",
        "'''\n",
        "Input:\n",
        "# Set the input data\n",
        "X = ([[0.1, 0.1], [0.1, 0.9],\n",
        "                [0.9, 0.1], [0.9, 0.9]])\n",
        "# Set the labels, the correct results for the xor operation\n",
        "Y = ([[0.1], [0.9], \n",
        "                 [0.9], [0.1]])\n",
        "Action:\n",
        "# Initialize the NeuralNetwork with\n",
        "# 3 input neurons\n",
        "# 4 hidden neurons\n",
        "# 1 output neuron\n",
        "\n",
        "# Fit the datas\n",
        "'''\n",
        "# YOUR CODE HERE\n",
        "X = [[0.1, 0.1], [0.1, 0.9],[0.9, 0.1], [0.9, 0.9]]\n",
        "x = np.array(X)\n",
        "Y = ([[0.1], [0.9],[0.9], [0.1]])\n",
        "y = np.array(Y)\n",
        "arch = np.array([3,4,1])\n",
        "neural = NeuralNetwork(arch)\n",
        "epochs =1000\n",
        "eta =0.06\n",
        "neural.fit(x, y, eta,epochs)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-cc45126e2c5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0meta\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m0.06\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mneural\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-63-26f4ec275ba2>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, Y, eta, epochs)\u001b[0m\n\u001b[1;32m     95\u001b[0m           \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m           \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeedforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m           \u001b[0mbackprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'feedforward' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "editable": false,
        "id": "-aYoNXSF2f9F",
        "nbgrader": {
          "checksum": "b1a894b26291672207fabd649f07486d",
          "grade": true,
          "grade_id": "cell-7391ad1a93e30118",
          "locked": true,
          "points": 3,
          "schema_version": 1,
          "solution": false
        },
        "colab": {}
      },
      "source": [
        "'''Testing for fit'''\n",
        "X = np.array([[0.1, 0.1], [0.1, 0.9],\n",
        "                [0.9, 0.1], [0.9, 0.9]])\n",
        "# Set the labels, the correct results for the xor operation\n",
        "Y = np.array([[0.1], [0.9], \n",
        "                 [0.9], [0.1]])\n",
        "nn1.fit(X,Y,1,10000)\n",
        "x = np.array([1,1,1]).reshape(-1, 1)\n",
        "y = np.array([[0],])\n",
        "print(nn1.feedforward(x),y)\n",
        "assert np.all(np.isclose(nn1.feedforward(x),y,atol=0.1))\n",
        "print('Test passed', '\\U0001F44D')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SLXYzUB4fs8o"
      },
      "source": [
        "## Plotting "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H2XKM2sufuwL",
        "colab": {}
      },
      "source": [
        "def plotting(X, Y):\n",
        "  x_plot = X.T\n",
        "  color = []\n",
        "  for i in Y:\n",
        "    if i[0] == 0:\n",
        "      color.append('g')\n",
        "    else:\n",
        "      color.append('r')\n",
        "  color = np.array(color)\n",
        "  print(x_plot)\n",
        "  plt.figure()\n",
        "  plt.xlabel('x1')\n",
        "  plt.ylabel('x2')\n",
        "  plt.scatter(x_plot[0],x_plot[1],color=color)\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PWvKv62qsiLP",
        "colab": {}
      },
      "source": [
        "plotting(X, Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "K1PPPHD9aDM-"
      },
      "source": [
        "## Could you test it now?\n",
        "\n",
        "Find the error between the predicted output and the desired output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XGQZuMbihk-1",
        "colab": {}
      },
      "source": [
        "def testing(X, Y):\n",
        "  ones = 0.9*np.ones((X.shape[0],1))\n",
        "  x_test = np.concatenate([ones, X], axis=1)\n",
        "  y_test = Y\n",
        "\n",
        "  for k in range(4):\n",
        "    print(nn.predict(x_test[k].reshape(-1, 1),y_test[k]))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "editable": false,
        "id": "vMqNNPopYjPI",
        "nbgrader": {
          "checksum": "4ff21be5bf4c5c721cbdbb0d612a9e0c",
          "grade": true,
          "grade_id": "cell-08caa0ed7b0ce465",
          "locked": true,
          "points": 2,
          "schema_version": 1,
          "solution": false
        },
        "colab": {}
      },
      "source": [
        "'''Testing the prediction'''\n",
        "x = np.array([0.9,0.9,0.9]).reshape(-1, 1)\n",
        "y = np.array([[0.1],])\n",
        "\n",
        "assert np.all(np.isclose(nn1.predict(x,y),0, atol=0.01))\n",
        "print('Test passed', '\\U0001F44D')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9-0oU2fCdhRN"
      },
      "source": [
        "# Advanced\n",
        "## Does the performance increase with increasing the number of neurons in the hidden layer?\n",
        "- Repeat the training with 1 neuron in the hidden layer, then with 3 neuron and then with 5 neuron in the hidden layer to see the trend in performance\n",
        "- Compare the training error\n",
        "- Compare the testing error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SNHBGSLBD_t2",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}